{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ML - Problem Set 2: Predicting Poverty\n",
        "\n",
        "El objetivo principal es construir un modelo predictivo de la pobreza de los hogares. Nótese que un hogar se clasifica como\n",
        "\n",
        "\\begin{equation}\n",
        "    Poor = I \\left( Inc < Pl \\right)\n",
        "\\end{equation}\n",
        "\n",
        "donde $I$ es una función indicadora que toma uno si el ingreso familiar está por debajo de una determinada línea de pobreza."
      ],
      "metadata": {
        "id": "3tH154dXq2df"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 1. Procesamiento de datos"
      ],
      "metadata": {
        "id": "ahg9cilhs_nk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "57HpxY2Iq0cO"
      },
      "outputs": [],
      "source": [
        "# Importar librerias\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar datos\n",
        "\n",
        "sample = pd.read_csv('sample_submission.csv')\n",
        "test_hogares = pd.read_csv('test_hogares.csv')\n",
        "train_hogares = pd.read_csv('train_hogares.csv')\n",
        "test_personas = pd.read_csv('test_personas.csv')\n",
        "train_personas = pd.read_csv('train_personas.csv')"
      ],
      "metadata": {
        "id": "ea5SW6xrrDY8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpiar datos\n",
        "\n",
        "common_columns_hogares = train_hogares.columns.intersection(test_hogares.columns) #obtener columnas comunes entre train_hogares y test_hogares\n",
        "common_columns_personas = train_personas.columns.intersection(test_personas.columns) #obtener columnas comunes entre train_personas y test_personas\n",
        "train_hogares = train_hogares[common_columns_hogares] #filtrar las columnas para alinear los datos\n",
        "train_personas = train_personas[common_columns_personas] #filtrar las columnas para alinear los datos\n",
        "\n",
        "columnas_deseadas = ['id', 'Orden', 'Clase', 'Dominio', 'P6020', 'P6040', 'P6050', 'P6090', 'P6100',\n",
        "                     'P6210', 'P6210s1', 'P6240', 'Oficio', 'P6426', 'P6430', 'P6590', 'P6800',\n",
        "                     'P6870', 'P6920', 'P7090', 'P7110', 'P7120', 'P7350', 'P7495', 'P7510s5',\n",
        "                     'Pet', 'Oc', 'Des', 'Ina', 'Fex_c', 'Depto', 'Fex_dpto'] #datos mas relevantes\n",
        "\n",
        "train_personas = train_personas[columnas_deseadas]\n",
        "test_personas = test_personas[columnas_deseadas]\n",
        "\n",
        "train_personas['P6210s1'] = train_personas['P6210s1'].where(train_personas['P6210s1'] <= 15, pd.NA) #eliminar nivel educativo 99\n",
        "test_personas['P6210s1'] = test_personas['P6210s1'].where(test_personas['P6210s1'] <= 15, pd.NA) #eliminar nivel educativo 99"
      ],
      "metadata": {
        "id": "TYpkQplBdJmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d29caaf-d8b0-4916-cc16-e807a0a86011"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-4931c81a3550>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_personas['P6210s1'] = test_personas['P6210s1'].where(test_personas['P6210s1'] <= 15, pd.NA) #eliminar nivel educativo 99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputar datos falntantes\n",
        "\n",
        "# Crear imputadores\n",
        "imputador_moda = SimpleImputer(strategy='most_frequent')  # Para variables categóricas\n",
        "imputador_mediana = SimpleImputer(strategy='median')  # Para variables numéricas\n",
        "\n",
        "# Función para imputar datos\n",
        "def imputar_datos(df):\n",
        "    # Separar columnas numéricas y categóricas\n",
        "    columnas_numericas = df.select_dtypes(include=['number']).columns\n",
        "    columnas_categoricas = df.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "    # Imputar numéricas con la mediana\n",
        "    if not columnas_numericas.empty:\n",
        "        df[columnas_numericas] = imputador_mediana.fit_transform(df[columnas_numericas])\n",
        "\n",
        "    # Imputar categóricas con la moda\n",
        "    if not columnas_categoricas.empty:\n",
        "        df[columnas_categoricas] = imputador_moda.fit_transform(df[columnas_categoricas])\n",
        "\n",
        "# Aplicar imputación a todos los DataFrames\n",
        "imputar_datos(test_hogares)\n",
        "imputar_datos(train_hogares)\n",
        "imputar_datos(test_personas)\n",
        "imputar_datos(train_personas)\n",
        "\n",
        "print(train_personas.columns.tolist())\n",
        "print(test_personas.columns.tolist())\n",
        "print(train_hogares.columns.tolist())\n",
        "print(test_hogares.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHuhxWYguyJl",
        "outputId": "b3912bc6-1772-4e33-adf1-7507e5d1d397"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['id', 'Orden', 'Clase', 'Dominio', 'P6020', 'P6040', 'P6050', 'P6090', 'P6100', 'P6210', 'P6210s1', 'P6240', 'Oficio', 'P6426', 'P6430', 'P6590', 'P6800', 'P6870', 'P6920', 'P7090', 'P7110', 'P7120', 'P7350', 'P7495', 'P7510s5', 'Pet', 'Oc', 'Des', 'Ina', 'Fex_c', 'Depto', 'Fex_dpto']\n",
            "['id', 'Orden', 'Clase', 'Dominio', 'P6020', 'P6040', 'P6050', 'P6090', 'P6100', 'P6210', 'P6210s1', 'P6240', 'Oficio', 'P6426', 'P6430', 'P6590', 'P6800', 'P6870', 'P6920', 'P7090', 'P7110', 'P7120', 'P7350', 'P7495', 'P7510s5', 'Pet', 'Oc', 'Des', 'Ina', 'Fex_c', 'Depto', 'Fex_dpto']\n",
            "['id', 'Clase', 'Dominio', 'P5000', 'P5010', 'P5090', 'P5100', 'P5130', 'P5140', 'Nper', 'Npersug', 'Li', 'Lp', 'Fex_c', 'Depto', 'Fex_dpto']\n",
            "['id', 'Clase', 'Dominio', 'P5000', 'P5010', 'P5090', 'P5100', 'P5130', 'P5140', 'Nper', 'Npersug', 'Li', 'Lp', 'Fex_c', 'Depto', 'Fex_dpto']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fusionar individuos con hogares"
      ],
      "metadata": {
        "id": "PecLHbWbtFQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una nueva variable que sea promedio educativo por hogar\n",
        "\n",
        "# Agrupar por 'id' y sumar los valores de 'P6210s1' para cada hogar\n",
        "promedio_educacion_train = train_personas.groupby('id')['P6210s1'].sum().reset_index()\n",
        "promedio_educacion_train.rename(columns={'P6210s1': 'Suma_P6210s1'}, inplace=True)\n",
        "\n",
        "# Unir con el DataFrame de hogares en base al 'id'\n",
        "train_hogares = train_hogares.merge(promedio_educacion_train, on='id', how='left')\n",
        "\n",
        "# Calcular el promedio de educación por hogar\n",
        "train_hogares['Promedio_Educacion'] = train_hogares['Suma_P6210s1'] / train_hogares['Nper']\n",
        "\n",
        "# Agrupar por 'id' y sumar los valores de 'P6210s1' para cada hogar\n",
        "promedio_educacion_test = test_personas.groupby('id')['P6210s1'].sum().reset_index()\n",
        "promedio_educacion_test.rename(columns={'P6210s1': 'Suma_P6210s1'}, inplace=True)\n",
        "\n",
        "# Unir con el DataFrame de hogares en base al 'id'\n",
        "test_hogares = test_hogares.merge(promedio_educacion_test, on='id', how='left')\n",
        "\n",
        "# Calcular el promedio de educación por hogar\n",
        "test_hogares['Promedio_Educacion'] = test_hogares['Suma_P6210s1'] / test_hogares['Nper']"
      ],
      "metadata": {
        "id": "9n1A97VN2O3g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estadistica descriptiva"
      ],
      "metadata": {
        "id": "ww9PaD924VnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aca generar estaditica descriptiva (cuando tengamos todos los datos unificados)"
      ],
      "metadata": {
        "id": "34TX3kzS4L6d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelos"
      ],
      "metadata": {
        "id": "3a1cYZKs4iY-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ppp8bwEZ4qQ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}